{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model for deployement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data set: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is about flowers. \n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.0703 - accuracy: 0.4417 - val_loss: 1.0744 - val_accuracy: 0.5667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0642 - accuracy: 0.5667 - val_loss: 1.0697 - val_accuracy: 0.5667\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0587 - accuracy: 0.5583 - val_loss: 1.0654 - val_accuracy: 0.5333\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0537 - accuracy: 0.5583 - val_loss: 1.0614 - val_accuracy: 0.5333\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 1.0491 - accuracy: 0.5333 - val_loss: 1.0577 - val_accuracy: 0.5333\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0449 - accuracy: 0.5250 - val_loss: 1.0544 - val_accuracy: 0.5000\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0414 - accuracy: 0.5167 - val_loss: 1.0513 - val_accuracy: 0.4000\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 1.0376 - accuracy: 0.5083 - val_loss: 1.0483 - val_accuracy: 0.3667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 1.0344 - accuracy: 0.4917 - val_loss: 1.0454 - val_accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 1.0315 - accuracy: 0.5083 - val_loss: 1.0427 - val_accuracy: 0.4000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 1.0289 - accuracy: 0.4833 - val_loss: 1.0403 - val_accuracy: 0.3000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 1.0261 - accuracy: 0.4667 - val_loss: 1.0380 - val_accuracy: 0.3000\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 1.0234 - accuracy: 0.5250 - val_loss: 1.0357 - val_accuracy: 0.3667\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 1.0210 - accuracy: 0.5417 - val_loss: 1.0335 - val_accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 1.0190 - accuracy: 0.5417 - val_loss: 1.0316 - val_accuracy: 0.3667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 1.0165 - accuracy: 0.5583 - val_loss: 1.0295 - val_accuracy: 0.3667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0145 - accuracy: 0.5500 - val_loss: 1.0276 - val_accuracy: 0.3667\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 1.0123 - accuracy: 0.5583 - val_loss: 1.0258 - val_accuracy: 0.4000\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0102 - accuracy: 0.5917 - val_loss: 1.0240 - val_accuracy: 0.4000\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0082 - accuracy: 0.5833 - val_loss: 1.0224 - val_accuracy: 0.3667\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0063 - accuracy: 0.6000 - val_loss: 1.0208 - val_accuracy: 0.4333\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0042 - accuracy: 0.6167 - val_loss: 1.0192 - val_accuracy: 0.4333\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0023 - accuracy: 0.6250 - val_loss: 1.0175 - val_accuracy: 0.4333\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0003 - accuracy: 0.6167 - val_loss: 1.0159 - val_accuracy: 0.4667\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.9983 - accuracy: 0.6250 - val_loss: 1.0143 - val_accuracy: 0.4667\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9963 - accuracy: 0.6250 - val_loss: 1.0127 - val_accuracy: 0.4667\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9944 - accuracy: 0.6333 - val_loss: 1.0112 - val_accuracy: 0.4667\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.9923 - accuracy: 0.6333 - val_loss: 1.0096 - val_accuracy: 0.4667\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.9904 - accuracy: 0.6417 - val_loss: 1.0081 - val_accuracy: 0.4667\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9884 - accuracy: 0.6417 - val_loss: 1.0066 - val_accuracy: 0.5000\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.9864 - accuracy: 0.6417 - val_loss: 1.0050 - val_accuracy: 0.5000\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9845 - accuracy: 0.6417 - val_loss: 1.0035 - val_accuracy: 0.5000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.9824 - accuracy: 0.6500 - val_loss: 1.0018 - val_accuracy: 0.5000\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9805 - accuracy: 0.6500 - val_loss: 1.0003 - val_accuracy: 0.5333\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.9784 - accuracy: 0.6583 - val_loss: 0.9987 - val_accuracy: 0.5333\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9764 - accuracy: 0.6583 - val_loss: 0.9972 - val_accuracy: 0.5333\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9744 - accuracy: 0.6667 - val_loss: 0.9956 - val_accuracy: 0.5333\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9724 - accuracy: 0.6667 - val_loss: 0.9941 - val_accuracy: 0.5667\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9705 - accuracy: 0.6667 - val_loss: 0.9926 - val_accuracy: 0.5667\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9684 - accuracy: 0.6667 - val_loss: 0.9910 - val_accuracy: 0.5667\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9663 - accuracy: 0.6667 - val_loss: 0.9893 - val_accuracy: 0.5667\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.9642 - accuracy: 0.6667 - val_loss: 0.9877 - val_accuracy: 0.5667\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9622 - accuracy: 0.6667 - val_loss: 0.9861 - val_accuracy: 0.5667\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9601 - accuracy: 0.6667 - val_loss: 0.9845 - val_accuracy: 0.5667\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.9580 - accuracy: 0.6667 - val_loss: 0.9829 - val_accuracy: 0.5667\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.9560 - accuracy: 0.6750 - val_loss: 0.9813 - val_accuracy: 0.5667\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.9539 - accuracy: 0.6750 - val_loss: 0.9797 - val_accuracy: 0.5667\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9517 - accuracy: 0.6833 - val_loss: 0.9781 - val_accuracy: 0.5667\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9496 - accuracy: 0.6833 - val_loss: 0.9764 - val_accuracy: 0.5667\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9475 - accuracy: 0.6833 - val_loss: 0.9748 - val_accuracy: 0.5667\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9453 - accuracy: 0.6833 - val_loss: 0.9731 - val_accuracy: 0.5667\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9433 - accuracy: 0.6833 - val_loss: 0.9715 - val_accuracy: 0.5667\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9411 - accuracy: 0.6833 - val_loss: 0.9700 - val_accuracy: 0.5667\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9389 - accuracy: 0.6833 - val_loss: 0.9683 - val_accuracy: 0.5667\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9368 - accuracy: 0.6833 - val_loss: 0.9665 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9347 - accuracy: 0.6833 - val_loss: 0.9648 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9325 - accuracy: 0.6833 - val_loss: 0.9631 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.9303 - accuracy: 0.6833 - val_loss: 0.9613 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9282 - accuracy: 0.6833 - val_loss: 0.9596 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9261 - accuracy: 0.6833 - val_loss: 0.9580 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9239 - accuracy: 0.6833 - val_loss: 0.9563 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9216 - accuracy: 0.6833 - val_loss: 0.9545 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.9194 - accuracy: 0.6833 - val_loss: 0.9526 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9173 - accuracy: 0.6833 - val_loss: 0.9509 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9152 - accuracy: 0.6833 - val_loss: 0.9492 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9129 - accuracy: 0.6833 - val_loss: 0.9474 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9108 - accuracy: 0.6833 - val_loss: 0.9457 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9086 - accuracy: 0.6833 - val_loss: 0.9439 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.9064 - accuracy: 0.6833 - val_loss: 0.9421 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.9042 - accuracy: 0.6833 - val_loss: 0.9403 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9021 - accuracy: 0.6833 - val_loss: 0.9384 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8999 - accuracy: 0.6833 - val_loss: 0.9366 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8978 - accuracy: 0.6833 - val_loss: 0.9348 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.8955 - accuracy: 0.6833 - val_loss: 0.9330 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.8934 - accuracy: 0.6833 - val_loss: 0.9311 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8912 - accuracy: 0.6833 - val_loss: 0.9293 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8890 - accuracy: 0.6833 - val_loss: 0.9274 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8868 - accuracy: 0.6833 - val_loss: 0.9255 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8846 - accuracy: 0.6833 - val_loss: 0.9237 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8824 - accuracy: 0.6833 - val_loss: 0.9219 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8802 - accuracy: 0.6833 - val_loss: 0.9201 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8781 - accuracy: 0.6833 - val_loss: 0.9184 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.8760 - accuracy: 0.6833 - val_loss: 0.9166 - val_accuracy: 0.6000\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8737 - accuracy: 0.6833 - val_loss: 0.9147 - val_accuracy: 0.6000\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8715 - accuracy: 0.6833 - val_loss: 0.9128 - val_accuracy: 0.6000\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8693 - accuracy: 0.6833 - val_loss: 0.9108 - val_accuracy: 0.6000\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8672 - accuracy: 0.6833 - val_loss: 0.9090 - val_accuracy: 0.6000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8650 - accuracy: 0.6833 - val_loss: 0.9070 - val_accuracy: 0.6000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8629 - accuracy: 0.6833 - val_loss: 0.9051 - val_accuracy: 0.6000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8607 - accuracy: 0.6833 - val_loss: 0.9032 - val_accuracy: 0.6000\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8585 - accuracy: 0.6833 - val_loss: 0.9014 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.8564 - accuracy: 0.6833 - val_loss: 0.8995 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8542 - accuracy: 0.6833 - val_loss: 0.8976 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.8520 - accuracy: 0.6833 - val_loss: 0.8957 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8500 - accuracy: 0.6833 - val_loss: 0.8939 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8478 - accuracy: 0.6833 - val_loss: 0.8922 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8456 - accuracy: 0.6833 - val_loss: 0.8902 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8435 - accuracy: 0.6833 - val_loss: 0.8883 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8414 - accuracy: 0.6833 - val_loss: 0.8864 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8393 - accuracy: 0.6833 - val_loss: 0.8846 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8372 - accuracy: 0.6833 - val_loss: 0.8827 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8351 - accuracy: 0.6833 - val_loss: 0.8809 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.8330 - accuracy: 0.6833 - val_loss: 0.8791 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8309 - accuracy: 0.6833 - val_loss: 0.8772 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8288 - accuracy: 0.6833 - val_loss: 0.8753 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8267 - accuracy: 0.6833 - val_loss: 0.8733 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8246 - accuracy: 0.6833 - val_loss: 0.8715 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.8226 - accuracy: 0.6833 - val_loss: 0.8697 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.8204 - accuracy: 0.6833 - val_loss: 0.8678 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8184 - accuracy: 0.6833 - val_loss: 0.8659 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 142us/sample - loss: 0.8163 - accuracy: 0.6833 - val_loss: 0.8640 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.8144 - accuracy: 0.6833 - val_loss: 0.8623 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.8123 - accuracy: 0.6833 - val_loss: 0.8604 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.8102 - accuracy: 0.6833 - val_loss: 0.8585 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8082 - accuracy: 0.6833 - val_loss: 0.8568 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8062 - accuracy: 0.6833 - val_loss: 0.8550 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.8042 - accuracy: 0.6833 - val_loss: 0.8531 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8022 - accuracy: 0.6833 - val_loss: 0.8514 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8002 - accuracy: 0.6833 - val_loss: 0.8496 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7982 - accuracy: 0.6833 - val_loss: 0.8478 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7962 - accuracy: 0.6833 - val_loss: 0.8461 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7942 - accuracy: 0.6833 - val_loss: 0.8442 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7922 - accuracy: 0.6833 - val_loss: 0.8422 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7903 - accuracy: 0.6833 - val_loss: 0.8404 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7883 - accuracy: 0.6833 - val_loss: 0.8386 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7863 - accuracy: 0.6833 - val_loss: 0.8369 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7844 - accuracy: 0.6833 - val_loss: 0.8351 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7825 - accuracy: 0.6833 - val_loss: 0.8335 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7806 - accuracy: 0.6833 - val_loss: 0.8318 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7787 - accuracy: 0.6833 - val_loss: 0.8301 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7767 - accuracy: 0.6833 - val_loss: 0.8283 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7750 - accuracy: 0.6833 - val_loss: 0.8262 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7730 - accuracy: 0.6833 - val_loss: 0.8247 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7711 - accuracy: 0.6833 - val_loss: 0.8230 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7692 - accuracy: 0.6833 - val_loss: 0.8212 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7674 - accuracy: 0.6833 - val_loss: 0.8194 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7656 - accuracy: 0.6833 - val_loss: 0.8178 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7637 - accuracy: 0.6833 - val_loss: 0.8161 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.7619 - accuracy: 0.6833 - val_loss: 0.8143 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7601 - accuracy: 0.6833 - val_loss: 0.8127 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7583 - accuracy: 0.6833 - val_loss: 0.8110 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7565 - accuracy: 0.6833 - val_loss: 0.8094 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.7547 - accuracy: 0.6833 - val_loss: 0.8077 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7529 - accuracy: 0.6833 - val_loss: 0.8060 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7512 - accuracy: 0.6833 - val_loss: 0.8045 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7494 - accuracy: 0.6833 - val_loss: 0.8028 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7477 - accuracy: 0.6833 - val_loss: 0.8013 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7459 - accuracy: 0.6833 - val_loss: 0.7996 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7442 - accuracy: 0.6833 - val_loss: 0.7980 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7425 - accuracy: 0.6833 - val_loss: 0.7965 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7407 - accuracy: 0.6833 - val_loss: 0.7948 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7390 - accuracy: 0.6833 - val_loss: 0.7931 - val_accuracy: 0.6000\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7373 - accuracy: 0.6833 - val_loss: 0.7915 - val_accuracy: 0.6000\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7357 - accuracy: 0.6833 - val_loss: 0.7899 - val_accuracy: 0.6000\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7340 - accuracy: 0.6833 - val_loss: 0.7884 - val_accuracy: 0.6000\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.7323 - accuracy: 0.6833 - val_loss: 0.7869 - val_accuracy: 0.6000\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7307 - accuracy: 0.6833 - val_loss: 0.7853 - val_accuracy: 0.6000\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7290 - accuracy: 0.6833 - val_loss: 0.7837 - val_accuracy: 0.6000\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7274 - accuracy: 0.6833 - val_loss: 0.7820 - val_accuracy: 0.6000\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7257 - accuracy: 0.6833 - val_loss: 0.7806 - val_accuracy: 0.6000\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7241 - accuracy: 0.6833 - val_loss: 0.7790 - val_accuracy: 0.6000\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7225 - accuracy: 0.6833 - val_loss: 0.7775 - val_accuracy: 0.6000\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7209 - accuracy: 0.6833 - val_loss: 0.7758 - val_accuracy: 0.6000\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7192 - accuracy: 0.6833 - val_loss: 0.7742 - val_accuracy: 0.6000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7177 - accuracy: 0.6833 - val_loss: 0.7727 - val_accuracy: 0.6000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7161 - accuracy: 0.6833 - val_loss: 0.7711 - val_accuracy: 0.6000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7145 - accuracy: 0.6833 - val_loss: 0.7696 - val_accuracy: 0.6000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7129 - accuracy: 0.6833 - val_loss: 0.7680 - val_accuracy: 0.6000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7114 - accuracy: 0.6833 - val_loss: 0.7664 - val_accuracy: 0.6000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.7098 - accuracy: 0.6833 - val_loss: 0.7650 - val_accuracy: 0.6000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7083 - accuracy: 0.6833 - val_loss: 0.7634 - val_accuracy: 0.6000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7067 - accuracy: 0.6833 - val_loss: 0.7619 - val_accuracy: 0.6000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.7053 - accuracy: 0.6833 - val_loss: 0.7606 - val_accuracy: 0.6000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7037 - accuracy: 0.6833 - val_loss: 0.7590 - val_accuracy: 0.6000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.7021 - accuracy: 0.6833 - val_loss: 0.7575 - val_accuracy: 0.6000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7007 - accuracy: 0.6833 - val_loss: 0.7561 - val_accuracy: 0.6000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6993 - accuracy: 0.6833 - val_loss: 0.7544 - val_accuracy: 0.6000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6977 - accuracy: 0.6833 - val_loss: 0.7530 - val_accuracy: 0.6000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.6963 - accuracy: 0.6833 - val_loss: 0.7516 - val_accuracy: 0.6000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6948 - accuracy: 0.6833 - val_loss: 0.7502 - val_accuracy: 0.6000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6933 - accuracy: 0.6833 - val_loss: 0.7487 - val_accuracy: 0.6000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6919 - accuracy: 0.6833 - val_loss: 0.7471 - val_accuracy: 0.6000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.6905 - accuracy: 0.6833 - val_loss: 0.7457 - val_accuracy: 0.6000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6890 - accuracy: 0.6833 - val_loss: 0.7445 - val_accuracy: 0.6000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6877 - accuracy: 0.6833 - val_loss: 0.7432 - val_accuracy: 0.6000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.6862 - accuracy: 0.6833 - val_loss: 0.7418 - val_accuracy: 0.6000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6848 - accuracy: 0.6833 - val_loss: 0.7405 - val_accuracy: 0.6000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6834 - accuracy: 0.6833 - val_loss: 0.7390 - val_accuracy: 0.6000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6820 - accuracy: 0.6833 - val_loss: 0.7376 - val_accuracy: 0.6000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.6806 - accuracy: 0.6833 - val_loss: 0.7363 - val_accuracy: 0.6000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6793 - accuracy: 0.6833 - val_loss: 0.7348 - val_accuracy: 0.6000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.6779 - accuracy: 0.6833 - val_loss: 0.7337 - val_accuracy: 0.6000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.6765 - accuracy: 0.6833 - val_loss: 0.7323 - val_accuracy: 0.6000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6752 - accuracy: 0.6833 - val_loss: 0.7311 - val_accuracy: 0.6000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6738 - accuracy: 0.6833 - val_loss: 0.7297 - val_accuracy: 0.6000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6725 - accuracy: 0.6833 - val_loss: 0.7285 - val_accuracy: 0.6000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6711 - accuracy: 0.6833 - val_loss: 0.7270 - val_accuracy: 0.6000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6698 - accuracy: 0.6833 - val_loss: 0.7255 - val_accuracy: 0.6000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.6685 - accuracy: 0.6833 - val_loss: 0.7240 - val_accuracy: 0.6000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6672 - accuracy: 0.6833 - val_loss: 0.7227 - val_accuracy: 0.6000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6659 - accuracy: 0.6833 - val_loss: 0.7213 - val_accuracy: 0.6000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6646 - accuracy: 0.6833 - val_loss: 0.7199 - val_accuracy: 0.6000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6633 - accuracy: 0.6833 - val_loss: 0.7187 - val_accuracy: 0.6000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.6621 - accuracy: 0.6833 - val_loss: 0.7175 - val_accuracy: 0.6000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6608 - accuracy: 0.6833 - val_loss: 0.7161 - val_accuracy: 0.6000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6595 - accuracy: 0.6833 - val_loss: 0.7148 - val_accuracy: 0.6000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6583 - accuracy: 0.6833 - val_loss: 0.7136 - val_accuracy: 0.6000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.6571 - accuracy: 0.6833 - val_loss: 0.7123 - val_accuracy: 0.6000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.6558 - accuracy: 0.6833 - val_loss: 0.7110 - val_accuracy: 0.6000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.6545 - accuracy: 0.6833 - val_loss: 0.7097 - val_accuracy: 0.6000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6533 - accuracy: 0.6833 - val_loss: 0.7086 - val_accuracy: 0.6000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6521 - accuracy: 0.6833 - val_loss: 0.7075 - val_accuracy: 0.6000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.6509 - accuracy: 0.6833 - val_loss: 0.7062 - val_accuracy: 0.6000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.6497 - accuracy: 0.6833 - val_loss: 0.7050 - val_accuracy: 0.6000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6485 - accuracy: 0.6833 - val_loss: 0.7039 - val_accuracy: 0.6000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6473 - accuracy: 0.6833 - val_loss: 0.7026 - val_accuracy: 0.6000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6461 - accuracy: 0.6833 - val_loss: 0.7014 - val_accuracy: 0.6000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6449 - accuracy: 0.6833 - val_loss: 0.7002 - val_accuracy: 0.6000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6437 - accuracy: 0.6833 - val_loss: 0.6991 - val_accuracy: 0.6000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6426 - accuracy: 0.6833 - val_loss: 0.6978 - val_accuracy: 0.6000\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6414 - accuracy: 0.6833 - val_loss: 0.6967 - val_accuracy: 0.6000\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6402 - accuracy: 0.6833 - val_loss: 0.6955 - val_accuracy: 0.6000\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.6391 - accuracy: 0.6833 - val_loss: 0.6943 - val_accuracy: 0.6000\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6379 - accuracy: 0.6833 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6368 - accuracy: 0.6833 - val_loss: 0.6920 - val_accuracy: 0.6000\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.6357 - accuracy: 0.6833 - val_loss: 0.6911 - val_accuracy: 0.6000\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6346 - accuracy: 0.6833 - val_loss: 0.6898 - val_accuracy: 0.6000\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.6334 - accuracy: 0.6833 - val_loss: 0.6884 - val_accuracy: 0.6000\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.6323 - accuracy: 0.6917 - val_loss: 0.6872 - val_accuracy: 0.6000\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6311 - accuracy: 0.6917 - val_loss: 0.6861 - val_accuracy: 0.6000\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6300 - accuracy: 0.6917 - val_loss: 0.6849 - val_accuracy: 0.6000\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.6289 - accuracy: 0.6917 - val_loss: 0.6837 - val_accuracy: 0.6000\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.6278 - accuracy: 0.6917 - val_loss: 0.6825 - val_accuracy: 0.6000\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.6267 - accuracy: 0.6917 - val_loss: 0.6815 - val_accuracy: 0.6000\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6256 - accuracy: 0.6917 - val_loss: 0.6801 - val_accuracy: 0.6000\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6245 - accuracy: 0.6917 - val_loss: 0.6790 - val_accuracy: 0.6000\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.6235 - accuracy: 0.6917 - val_loss: 0.6778 - val_accuracy: 0.6000\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6224 - accuracy: 0.6917 - val_loss: 0.6768 - val_accuracy: 0.6000\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.6213 - accuracy: 0.6917 - val_loss: 0.6757 - val_accuracy: 0.6000\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6202 - accuracy: 0.6917 - val_loss: 0.6744 - val_accuracy: 0.6000\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6192 - accuracy: 0.6917 - val_loss: 0.6732 - val_accuracy: 0.6000\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.6181 - accuracy: 0.6917 - val_loss: 0.6721 - val_accuracy: 0.6000\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.6171 - accuracy: 0.6917 - val_loss: 0.6710 - val_accuracy: 0.6000\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.6161 - accuracy: 0.6917 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6150 - accuracy: 0.6917 - val_loss: 0.6688 - val_accuracy: 0.6000\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6140 - accuracy: 0.6917 - val_loss: 0.6676 - val_accuracy: 0.6000\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.6130 - accuracy: 0.6917 - val_loss: 0.6668 - val_accuracy: 0.6000\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6120 - accuracy: 0.6917 - val_loss: 0.6658 - val_accuracy: 0.6000\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.6110 - accuracy: 0.6917 - val_loss: 0.6648 - val_accuracy: 0.6000\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6099 - accuracy: 0.6917 - val_loss: 0.6637 - val_accuracy: 0.6000\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.6090 - accuracy: 0.6917 - val_loss: 0.6627 - val_accuracy: 0.6000\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.6080 - accuracy: 0.6917 - val_loss: 0.6614 - val_accuracy: 0.6000\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6069 - accuracy: 0.7000 - val_loss: 0.6602 - val_accuracy: 0.6333\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6062 - accuracy: 0.7000 - val_loss: 0.6595 - val_accuracy: 0.6333\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6050 - accuracy: 0.7000 - val_loss: 0.6584 - val_accuracy: 0.6333\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.6039 - accuracy: 0.7000 - val_loss: 0.6572 - val_accuracy: 0.6333\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.6030 - accuracy: 0.7000 - val_loss: 0.6560 - val_accuracy: 0.6333\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.6020 - accuracy: 0.7000 - val_loss: 0.6550 - val_accuracy: 0.6333\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.6011 - accuracy: 0.7000 - val_loss: 0.6536 - val_accuracy: 0.6333\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6000 - accuracy: 0.7000 - val_loss: 0.6528 - val_accuracy: 0.6333\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5991 - accuracy: 0.7000 - val_loss: 0.6517 - val_accuracy: 0.6333\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5980 - accuracy: 0.7000 - val_loss: 0.6509 - val_accuracy: 0.6333\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5970 - accuracy: 0.7000 - val_loss: 0.6499 - val_accuracy: 0.6333\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5959 - accuracy: 0.7000 - val_loss: 0.6489 - val_accuracy: 0.6333\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5947 - accuracy: 0.7000 - val_loss: 0.6481 - val_accuracy: 0.6333\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.5936 - accuracy: 0.7000 - val_loss: 0.6473 - val_accuracy: 0.6333\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.5924 - accuracy: 0.7000 - val_loss: 0.6468 - val_accuracy: 0.6333\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5912 - accuracy: 0.7000 - val_loss: 0.6461 - val_accuracy: 0.6333\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.5902 - accuracy: 0.7000 - val_loss: 0.6453 - val_accuracy: 0.6333\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5892 - accuracy: 0.7000 - val_loss: 0.6444 - val_accuracy: 0.6333\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5883 - accuracy: 0.7000 - val_loss: 0.6436 - val_accuracy: 0.6333\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5872 - accuracy: 0.7000 - val_loss: 0.6422 - val_accuracy: 0.6333\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.78 - 0s 117us/sample - loss: 0.5861 - accuracy: 0.7000 - val_loss: 0.6411 - val_accuracy: 0.6333\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5851 - accuracy: 0.7000 - val_loss: 0.6398 - val_accuracy: 0.6333\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5840 - accuracy: 0.7000 - val_loss: 0.6386 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.5830 - accuracy: 0.7000 - val_loss: 0.6371 - val_accuracy: 0.6333\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5819 - accuracy: 0.7000 - val_loss: 0.6359 - val_accuracy: 0.6333\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.5809 - accuracy: 0.7000 - val_loss: 0.6349 - val_accuracy: 0.6333\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5798 - accuracy: 0.7000 - val_loss: 0.6339 - val_accuracy: 0.6333\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5787 - accuracy: 0.7000 - val_loss: 0.6327 - val_accuracy: 0.6333\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5776 - accuracy: 0.7000 - val_loss: 0.6316 - val_accuracy: 0.6333\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5765 - accuracy: 0.7000 - val_loss: 0.6305 - val_accuracy: 0.6333\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5754 - accuracy: 0.7000 - val_loss: 0.6293 - val_accuracy: 0.6333\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5743 - accuracy: 0.7083 - val_loss: 0.6281 - val_accuracy: 0.6333\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5733 - accuracy: 0.7083 - val_loss: 0.6272 - val_accuracy: 0.6333\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.5721 - accuracy: 0.7083 - val_loss: 0.6260 - val_accuracy: 0.6333\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5710 - accuracy: 0.7083 - val_loss: 0.6246 - val_accuracy: 0.6333\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5699 - accuracy: 0.7083 - val_loss: 0.6233 - val_accuracy: 0.6333\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5689 - accuracy: 0.7083 - val_loss: 0.6220 - val_accuracy: 0.6333\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5678 - accuracy: 0.7083 - val_loss: 0.6206 - val_accuracy: 0.6333\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5668 - accuracy: 0.7167 - val_loss: 0.6192 - val_accuracy: 0.6333\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.5655 - accuracy: 0.7167 - val_loss: 0.6182 - val_accuracy: 0.6333\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.5644 - accuracy: 0.7167 - val_loss: 0.6171 - val_accuracy: 0.6333\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5633 - accuracy: 0.7167 - val_loss: 0.6160 - val_accuracy: 0.6333\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.5623 - accuracy: 0.7250 - val_loss: 0.6146 - val_accuracy: 0.6333\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.5611 - accuracy: 0.7250 - val_loss: 0.6135 - val_accuracy: 0.6333\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5599 - accuracy: 0.7250 - val_loss: 0.6125 - val_accuracy: 0.6333\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5588 - accuracy: 0.7250 - val_loss: 0.6114 - val_accuracy: 0.6333\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5578 - accuracy: 0.7250 - val_loss: 0.6104 - val_accuracy: 0.6333\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5566 - accuracy: 0.7250 - val_loss: 0.6093 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x203fbbdaac8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.070269</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>1.074426</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.064213</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1.069710</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.058741</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>1.065439</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.053747</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>1.061370</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.049104</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.057692</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.561070</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.613523</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.559938</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.612511</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.558826</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.611442</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.557750</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.610363</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.556563</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.609275</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.070269  0.441667  1.074426      0.566667\n",
       "1    1.064213  0.566667  1.069710      0.566667\n",
       "2    1.058741  0.558333  1.065439      0.533333\n",
       "3    1.053747  0.558333  1.061370      0.533333\n",
       "4    1.049104  0.533333  1.057692      0.533333\n",
       "..        ...       ...       ...           ...\n",
       "295  0.561070  0.725000  0.613523      0.633333\n",
       "296  0.559938  0.725000  0.612511      0.633333\n",
       "297  0.558826  0.725000  0.611442      0.633333\n",
       "298  0.557750  0.725000  0.610363      0.633333\n",
       "299  0.556563  0.725000  0.609275      0.666667\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2548a518208>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2548c5e7080>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXyU5b338c+VPYQlISyyh1UWAYGwKAoo1WKLoh6ttNYqrXI8Lq34tLW1tdKj7bFWe9TWR4sW9+X46PGpx1qtKEJBEEGRVSBsEvaQTEjIDMkk1/ljJskQMskkmcnMPfN9v155zcy9/u7c4cc1130txlqLiIg4X1K0AxARkfBQQhcRiRNK6CIicUIJXUQkTiihi4jEiZRonbhbt242Ly8vWqcXEXGkdevWFVlruze2LmoJPS8vj7Vr10br9CIijmSM2RtsnapcRETihBK6iEicUEIXEYkTUatDb0xVVRWFhYV4PJ5ohyJARkYGffv2JTU1NdqhiEgIYiqhFxYW0qlTJ/Ly8jDGRDuchGat5dixYxQWFjJw4MBohyMiIWi2ysUYs9gYc8QYsynIemOMecwYU2CM2WCMGd/aYDweD7m5uUrmMcAYQ25urr4tiThIKHXozwKzmlh/CTDU/zMfeKItASmZxw7dCxFnabbKxVq73BiT18Qmc4DnrW8c3tXGmGxjTC9r7cEwxSjiXJUn4JM/Q5U72pEklv5TYMjM0LcvPwLrnoXqqtPXZWbD5H+DpNhvQxKOOvQ+wL6Az4X+ZacldGPMfHylePr37x+GU4vEuJ1L4YNf+z/oG0/7sJA7FG5vQcfFDf8FS3/j/xB4n/zzRQycBmeMDleAEROOhN7YX2mjs2ZYaxcBiwDy8/MTemYNr9dLSkpMPZOWSHAX+17v2ATZ/aIbS6J4ewFs+WvL9qkohqQUuKcIAqsa96yAZ7/pW+8A4fgOUQgE/qX2BQ6E4bhRc/nllzNhwgRGjRrFokWLAHj33XcZP348Y8eOZeZM31e58vJy5s2bx+jRoxkzZgxvvPEGAB07dqw71uuvv84NN9wAwA033MCdd97JBRdcwF133cWaNWs499xzGTduHOeeey7btm0DoLq6mh//+Md1x/3jH//IBx98wBVXXFF33Pfff58rr7yyPX4d0hZul+81Mzu6cSSSjGzf770ls7F5XL79Gj43ysiuX+8A4SgivgXcZox5FZgMlIaj/vzX/7OZLQeOtzm4QCN7d+beS0c1u93ixYvp2rUrbrebiRMnMmfOHG666SaWL1/OwIEDKS72/W9933330aVLFzZu3AhASUlJs8fevn07S5YsITk5mePHj7N8+XJSUlJYsmQJd999N2+88QaLFi1i9+7dfP7556SkpFBcXExOTg633norR48epXv37jzzzDPMmzevbb8QiTx3CZhkSOvY/LYSHpnZYKuhshzSO4W2j9vV+H+6tcvccZLQjTGvADOAbsaYQuBeIBXAWvsk8A7wDaAAqAAcn2Uee+wx3nzzTQD27dvHokWLmDZtWl177K5duwKwZMkSXn311br9cnJymj321VdfTXJyMgClpaVcf/317NixA2MMVVVVdce9+eab66pkas933XXX8eKLLzJv3jxWrVrF888/H6Yrlojx+BOFWgy1n9pStbukBQm9pH6/YMdygFBauXy7mfUWuDVsEfmFUpKOhI8++oglS5awatUqOnTowIwZMxg7dmxddUgga22jTfsClzVsx52VlVX3/p577uGCCy7gzTffZM+ePcyYMaPJ486bN49LL72UjIwMrr76atXBO4Hb1XiikMgJLFVnh9j4wuOCDrmnL0/L8tWtO6TKJfbb4bSz0tJScnJy6NChA19++SWrV6/m5MmTLFu2jN27dwPUVblcfPHF/OlPf6rbt7bKpWfPnmzdupWampq6kn6wc/Xp0weAZ599tm75xRdfzJNPPonX6z3lfL1796Z3797cf//9dfXyEuM8Lshs/pubhFHt77slSTjYf7zG1NfJO4ASegOzZs3C6/UyZswY7rnnHqZMmUL37t1ZtGgRV155JWPHjuWaa64B4Je//CUlJSWcddZZjB07lqVLlwLwwAMPMHv2bC688EJ69eoV9Fw//elP+fnPf87UqVOprq6uW37jjTfSv39/xowZw9ixY3n55Zfr1l177bX069ePkSNHRug3IGEVrG5WIiejFfXenibuU2a2Y0roxrbkSXAY5efn24YTXGzdupURI0ZEJR6nuO222xg3bhw/+MEP2uV8uidt9Ng46D0ervpLtCNJHK6v4JHRcNkfYfz3mt++pgbuy4Xz7oSZ95y+/qmZvrr47/3/8MfaCsaYddba/MbWqRLWQSZMmEBWVhYPP/xwtEORULlLVEJvby0toVeWga1puoRecSw8sUWYErqDrFu3LtohSEvU1ICnVA9F21t6J19T0VCrSer6CgR51pGZA8d2hie2CFMdukikNFfyk8gwBjK6hF5Cr038wf7jzXBOHboSukikNFfyk8jJzGlFCb2ph6Klvm9cMU4JXSRSmiv5SeRktqCpYSgldFvj+8YV41SHLtJWVR7fIE41DYZePbzZ96oql/aXkQ2uvbDt781vu2el77WpEjrAlrcgq1t44us6CLqfGZ5jBVBCF2mrL172jfAXTOc+7ReL+HTpCzs/gFfmhrZ9SmbjPUUBuvjHHnzrtvDEBjD1Drjo181v10JK6G3QsWNHysvLox2GRFvZId/rTR+CaVCLmdEFumpO1nZ3ye8gvwXDSmX1gNTMxtcNnAa3fALeME5SktUjfMcKoIQeBzS2epS5XZDeGfpMiHYkUis1E3qPC8+xjIEew8NzrAiL3Szw95/BoY3hPeYZo+GSB4KuvuuuuxgwYAC33HILAAsXLsQYw/LlyykpKaGqqor777+fOXPmNHuq8vJy5syZ0+h+zz//PA899BDGGMaMGcMLL7zA4cOHufnmm9m1axcATzzxBL1792b27Nls2uSbn/uhhx6ivLychQsXMmPGDM4991xWrlzJZZddxrBhw7j//vuprKwkNzeXl156iZ49e1JeXs7tt9/O2rVrMcZw77334nK52LRpE//5n/8JwFNPPcXWrVv5wx/+0KZfb8Jqqtu4xKz9Ljevry2kJgq95SfmdeW8oWGqjw8Quwk9CubOncsdd9xRl9Bfe+013n33XRYsWEDnzp0pKipiypQpXHbZZc1OoJyRkcGbb7552n5btmzhN7/5DStXrqRbt251A2/98Ic/ZPr06bz55ptUV1dTXl7e7PjqLpeLZcuWAb6BwVavXo0xhqeffpoHH3yQhx9+uNEx29PS0hgzZgwPPvggqampPPPMM/z5z39u668vcWlERUd68qOdvLB6b1TOffP0wQmW0JsoSUfKuHHjOHLkCAcOHODo0aPk5OTQq1cvFixYwPLly0lKSmL//v0cPnyYM844o8ljWWu5++67T9vvww8/5KqrrqJbN9/NrB3r/MMPP6wb3zw5OZkuXbo0m9BrBwkDKCws5JprruHgwYNUVlbWjd0ebMz2Cy+8kLfffpsRI0ZQVVXF6NGxP19izFIJ3ZFWFBRx4fAeLL5hYrRDCZvYTehRctVVV/H6669z6NAh5s6dy0svvcTRo0dZt24dqamp5OXlnTbGeWOC7RdsrPPGpKSkUBPQmaGpsdVvv/127rzzTi677DI++ugjFi5cCAQfW/3GG2/kt7/9LcOHD9fMR23ldkWkCZpETmFJBbuLTnDdlAHRDiWslNAbmDt3LjfddBNFRUUsW7aM1157jR49epCamsrSpUvZuze0r2ilpaWN7jdz5kyuuOIKFixYQG5uLsXFxXTt2pWZM2fyxBNPcMcdd1BdXc2JEyfo2bMnR44c4dixY3Ts2JG3336bWbNmBT1f7djqzz33XN3y2jHbH3nkEcBX5ZKTk8PkyZPZt28fn332GRs2bGjLr0xUQo9ZS788wouNVKsUlZ8EiEi1RzSpp2gDo0aNoqysjD59+tCrVy+uvfZa1q5dS35+Pi+99BLDh4f2tDvYfqNGjeIXv/gF06dPZ+zYsdx5550APProoyxdupTRo0czYcIENm/eTGpqKr/61a+YPHkys2fPbvLcCxcu5Oqrr+b888+vq86B4GO2A3zrW99i6tSpIU2dJ0FYqzr0GPb40gLW7CnmcJnnlJ9qa7l0bG+G9oivuV41HnoCmz17NgsWLGDmzJlBt9E9aUZlBfy2F8y8F86/M9rRSIAyTxVn//v7/Ou0Qfx0ljOaHYaiqfHQVUJPQC6Xi2HDhpGZmdlkMpcQeJoZ2Emi5pNdxVTX2LirVmmK6tDbaOPGjVx33XWnLEtPT+eTTz6JUkTNy87OZvv27dEOIz64NQBXpNz43Fo2FLZ+2NqKymoyUpMY3z9xqhRjLqG3pBVILBg9ejTr16+PdhgREa3qOEdRCT0i9hVXsGTrYc4ZlEtetw6tPs64/jlkpCaHMbLYFlMJPSMjg2PHjpGbm+uopB6PrLUcO3aMjIyMaIcS21RCj4iVBUUA/PucUQzt2SnK0ThHTCX0vn37UlhYyNGjR6MdiuD7D7Zv377RDiO2FfunJkuQEnrxiUq87TDRw9JtR+jZOZ0hcdYKJdJiKqGnpqbW9XAUiXnrX4Z//NL3PtjQq3HkrS8O8MNXPm+38105vo++qbdQTCV0EUcp2uF7/c5rvmFy49x7mw/RrWM6d3xtaMTPZQx8bUTPiJ8n3iihi7SWxwUdusGwr0c7koirqbF8XFDEBcN78N046y4fT9QOXaS13InT5X/LweOUVFRxfgK16XYiJXSR1nKXJEzrln/u8LU6mTpYCT2WKaGLtFYCDcq1sqCIM3t2okdnNWONZUroIq2VIINyeaqqWbOnmKlDVDqPdXooKtJacVJC33m0nL9tOEiwjsGHyzxUemtUf+4ASugirVFTA57SuCihP/jul7y3+XCT2/TsnM6kgV3bKSJpLSV0kdaoLANb4/gSenWN5eOdx/hWfl8euHJM0O2MQZ18HEAJXaQ1asdwyXT2SH4b95dS5vFy3tDuJCUpYTudErpIa3icPSjXB1sP88qafex3uQGYOjj+hy5IBGrlItIabmcPm/vYhwV8svsYBvjulP7kdkyPdkgSBiGV0I0xs4BHgWTgaWvtAw3W5wCLgcGAB/i+tXZTmGMViR0OLqGXVlSxsdDF7RcOZcFFw6IdjoRRsyV0Y0wy8DhwCTAS+LYxZmSDze4G1ltrxwDfw5f8ReKXu8T36sAS+qpdRdTY+JvxXkIroU8CCqy1uwCMMa8Cc4AtAduMBP4DwFr7pTEmzxjT01rbdFsokVi05in45x+a3qbyhO+1HUvo1lpueOZTth0qa9Nxyk96yUpL5ux+zvvPSJoWSkLvA+wL+FwITG6wzRfAlcAKY8wkYADQFzgloRtj5gPzAfr379/KkEUibOeH4PXA8G82vV3uYEhvvwkYdh4tZ9n2o0wdkkvf7NZPywYwcWBXUpP1CC3ehJLQG2vL1LBP2QPAo8aY9cBG4HPAe9pO1i4CFgHk5+drwkqJTW4X9BgJc/4U7UhOUTtA1gNXjqFf17YldIlPoST0QqBfwOe+wIHADay1x4F5AMbX+2C3/0fEeTwu6DqoXU954qSXisrqJrf5aNtRBuR2UDKXoEJJ6J8CQ40xA4H9wFzgO4EbGGOygQprbSVwI7Dcn+RFnKedB906WOpm+u8/otLb/Fyd105WVaUE12xCt9Z6jTG3Ae/ha7a42Fq72Rhzs3/9k8AI4HljTDW+h6U/iGDMIpHVzoNuLdt2lEpvDT/5+pl0zkwNul2SgYtHntFucYnzhNQO3Vr7DvBOg2VPBrxfBUR+okGRSPNWQlVFuyb0fxYU0bNzOrfMGKzxUqRN9JhbJFA7dxiqnatz6pBuSubSZkroIoHaedAtzdUp4aSELhKotgdoO5XQ6+bq1GxAEgZK6CKBPO076FbdXJ2dNFentJ0Sukggd/vUoVfXWJ5duZtP9xRrTBUJGyV0kUDtVEL//KsSFv7PFmqsZdZZaooo4aEJLkQC1ZXQu0T0NHuPVQDw9x9NY0iP9hsPRuKbSugigTwuSOsIycE7+ITD3uIKjIF+XTMjeh5JLCqhS+JYuxgKPvC9H30VjLqift2Wt2DDf8HBDWGvPy8+UcmjS7bzk1nD6Zju+ye3r7iC3l0ySU9JDuu5JLEpoUviWP0ElB2GGi94Sk9N6GsXw75PfINyDb0orKf96/r9PLdqL2f3z+aKcX0B+Kq4QqVzCTsldEkcXg+ceQmcPA6ufaeu87hgwFT47uthP+3KAl9b83/uKDoloV9wZvewn0sSm+rQJXFUeSA1w1elUtuapZa7JCItW6qqa1i9qxjwJXZrLe7Kao6WnWRAblbYzyeJTSV0SRzek5CSAakd6nuE1gpxyNx3Nh7kN3/birWhzc/irbGUn/QyfVh3lm0/yjn/8SE1/n01rrmEmxK6JA6vuz6hV5ZDdZWvNUtNja9OPYQS+n99uo+T3mouOLNHyKftmJHCv80YzJ8+LMDtn8QiMy2Z6UNV5SLhpYQuiaGmBqorfQm9NnF7SiGrm69OHdtsCf2kt5o1u4u5ZmI/Fl42qsUh/Pucs1oRuEjoVIcuicHr8b3W1qFDfSciT2gjLH6214W7qloDaUnMUkKXxFCb0FMyA0ro/kTuDq27/8qCIpKTDFMGdY1QkCJto4QuiaEuoaefXkIPccjcfxYUcXa/bDplRLYXqUhrKaFLYqhy+15TM+urVjwNq1yCJ/TSiio2Fro4T9UtEsOU0CUxeE/6XlPS6xN3bck8hCFzV+0qosaioW4lpimhS2Lw+kvoKZn1ibsFJfQVBUVkpSVzdr/2mzxapKWU0CUx1JbQUzMgJc3fuSjgoWiyf1kQK3YUMWVQLqnJ+icjsUt/nZIYauvQU/xTvQV2//f4e4ka0+iu+4or2HOsQtUtEvPUsUgSQ10duj+hZ2ZD4TpY/hAUrj2lumXboTKWbD18ymdAD0Ql5imhS2LwNiih9xoLX7wCH97n+3zWVXWb3vf2Flb4R0isNfyMTppZSGKeErokhqqAnqIAlz8Blz5Wv94/Q5Gnqpo1e4q54dw87v7GiLrVKUkGE6RKRiRWKKFLYqjrWORP6Mb4Ho42sHZPCZXeGqYP605aih4xibMooUtiaJjQG/HupkM8smQ7qcmGSQPVvV+cR0UQSQx1g3MFn/btkSXb2e9yc/05eWSlq6wjzqO/WkkMVR7A+NqbN+JImYcvD5Vx16zh/NuMwe0bm0iYqIQuicHr8VW3BHmw+XHBMUBNE8XZVEKXxOD1+MZxacRjH+zgqeW7yO6Qysjends5MJHwUUKXxOD1NFp/bq3l+VV76dklg1svGExykpominOpykUSQ5Wn0RYu2w6XUVR+kvnTBnHFuL5RCEwkfFRCF0fyVFXXTbgciizPCZKT0zl+ovKU5R9sPQLA+RqnReKAEro4TpmnivN+t5RSd1XI+yxO3U+uqWTOfe+ftm5w9yx6dQnenFHEKUJK6MaYWcCjQDLwtLX2gQbruwAvAv39x3zIWvtMmGMVAWD1rmJK3VX867RB9OoSvKNQoBFrU0myXVg4ceRp6/Lz1IlI4kOzCd0Ykww8DlwEFAKfGmPestZuCdjsVmCLtfZSY0x3YJsx5iVrbWUjhxRpkxU7jpKZmsydFw8jPSU5tJ22GkjL5oapAyMbnEgUhVJCnwQUWGt3ARhjXgXmAIEJ3QKdjG/0oo5AMeANc6wSh2pqLGv3luCpCr0+/KPtR5k0sGtoybzskG/iCq8bOuS2IVKR2BdKQu8D7Av4XAhMbrDNn4C3gANAJ+Aaa21NwwMZY+YD8wH69+/fmnglzizZepj5L6xr8X43nJsX2obPXw555/kmuGii279IPAgloTfWMNc2+Px1YD1wITAYeN8Y809r7fFTdrJ2EbAIID8/v+ExJAEt236UrLRknvv+pGCdOE+TnJTEWaF2ACot9P14SiGjS+sDFXGAUBJ6IdAv4HNffCXxQPOAB6y1FigwxuwGhgNrwhKlxK2VBUWcMzg3Mg8mq6ugsgzcJb55Q5uYBFokHoTSsehTYKgxZqAxJg2Yi696JdBXwEwAY0xP4ExgVzgDlfhy4qSXx5cWsOdYBVMjNX6Kp9T3evwA1FT55g0ViWPNltCttV5jzG3Ae/iaLS621m42xtzsX/8kcB/wrDFmI74qmrustUVBDyoJ778/38/v39tGRmoSM4f3jMxJ3P5JoI8X+l5VQpc4F1I7dGvtO8A7DZY9GfD+AHBxeEOTeLZix1H6ZGey7CczSEmO0AgUHn9Cr30+n5kTmfOIxAiN5SLtzltdw8c7j3HekG6RS+ZQX0KvpSoXiXPq+i+t9nFBES9+spdRvbswZVBX/rJiNzaEtksVldWUebycF+nxUzwNErqqXCTOKaFLqz3+UQErC47x902HmJjXlQ2FLvp37RDSvhPzcpg2rHtkA3SXnPpZJXSJc0ro0iqeqmo+3VPC+P7ZfPaVizW7i7kmvx+/u2pMtEOr17DKRSV0iXOqQ5dWWbunhEpvDbfMGEIn/4TKEa9CaanAKheTBGmdoheLSDtQQpcWe2H1Xm5/5TNSkw3nDsllymDfGCkRa0/eWoEl9IwukKQ/d4lvqnKRFntp9V6y0lNYcNEwOqSlcPuFQzh/aDe6ZqVFO7RTeVzQqTeUHVCTRUkIKrJIixwp8/DloTKunTyA752TB8CYvtl172OK2wXZ/kHg9EBUEoASurTIygJfB+DzYq16pTEel2/I3PTOeiAqCUEJXVpkxY5jZHdIZVSoox22tyfOg0/+7HvvLvEl8qxukBXhJpIiMUB16BIyay0rCo4ydXA3kpJCHOu2PdVUw+GNcGij77Pb5atquWoxZGqaOYl/SugSsp1Hyzl8/GTsNU+sVTu6osflGzq36oSvhN57XHTjEmknSujSpKLyk3x5sAyApduOADFcf17bM9Ttqm+yqIehkkCU0KVJP3r1c1YWHKv7PLh7Fv1C7N7f7mo7Enlc9e/1MFQSiBK6BHXipJc1u4v5l/F9mTvJN2nVgNwYTeZQXyp3l6qELglJCV2CWrO7mKpqy+XjejMxElPEhVttqdxdUl/9og5FkkDUbFEatX6fi7+s2E1aSpIzkjnUl8ory6DCP2GWqlwkgaiELo368f/7goIj5XxzdC8yUpOjHU5oAgfjcn3le1WViyQQJXQ5zcFSNwVHyrlr1nBunj4o2uGELnD885I9vleV0CWBqMpFTrNih6+6YsaZ3TEmBjsQBRM4umLJHkjNguTUqIUj0t5UQk9gf1mxm8/2lpy2fMvB43TrmMaZPR02fnhglUvxbpXOJeEooSeoEye9PPD3rXTJTCO7w6ml2OQkw/fPGxib3fub4nb5uvi7i6H8EPQYFe2IRNqVEnqCWrPH1yTxkWvOjt2u/C3lcUFOni+hg0roknBUh56gVuwoIi0lify8OGqn7S6FnAH1n9XCRRKMSugJ5paX1rFp/3GOlHmYmJfjnCaJwVgLL38LirbD8ULo+A1IToPqSpXQJeEooSeQfcUVvLPxEPkDcpgwIIdrJvaLdkhtV3kCdvwDep0NY86Bsd+G7AFw8AsYf320oxNpV0roCWSFf7ah/7hyNEOd1oIlmNqWLfnzYMINvve9z45aOCLRpITuIJ6qaiqra1q9/7JtR+nZOZ0hPTqGMaoo0yBcInWU0B3iy0PHmf3YCrw1tk3H+ZfxfZ3VWag5dYNwKaGLKKE7xPubD+Otsfz8kuEkt7J9uDGGS846I8yRRZlHJXSRWkroDrGioIhRvTvzr9MHRzuU2FJb5aJhckXUDt0JTpz08tlXJfHTASicNDORSB0ldAeo7dUZs3N5RpPbBSYJ0uKk1Y5IGyihO0Btr07HTDTRnjwuyOgCSfpTFtG/AgdYWVDEpLyuzu/VGQlulx6IivjpoWiUlZyo5I3PCqkO0hzRW2P58lAZd83q086ROYTHpfpzET8l9Ch79uM9PPrBjia3SUtO4qKRPdopIodxu9TCRcQvpIRujJkFPAokA09bax9osP4nwLUBxxwBdLfWFocx1ri0oqCIMX278Or8KUG3SUlKIi1FtWON8rggu3+0oxCJCc1mCWNMMvA4cAkwEvi2MWZk4DbW2t9ba8+21p4N/BxYpmTevOOeKtbvc3H+0G50SEsJ+qNk3gR3iapcRPxCKaFPAgqstbsAjDGvAnOALUG2/zbwSnjCi1/bD5dx/9+2Ul1jOW9I92iHEx0niuD9e6GqovXHcJfooaiIXygJvQ+wL+BzITC5sQ2NMR2AWcBtQdbPB+YD9O+f2F+Tn/t4D6t2FjF1SC4TBiRoHfDuZbD+Rd9wt8lprTtGt2EwcFp44xJxqFASemMDhwQbIepSYGWw6hZr7SJgEUB+fn7bRplyuBUFRUwf1p2nr58Y7VCip7bb/vffhc69oxuLSBwIpXK2EAicCaEvcCDItnNRdUuz9hVXsPdYhXp+ejQOi0g4hVJC/xQYaowZCOzHl7S/03AjY0wXYDrw3bBGGIIDLjc/eG4t7kpve5+6VSoqqwE0NovbBcnpkJoZ7UhE4kKzCd1a6zXG3Aa8h6/Z4mJr7WZjzM3+9U/6N70C+Ie19kTEog3i3U2H2HrwON8c04uUVg4t29765mQyuHscTTTRGuoUJBJWIbVDt9a+A7zTYNmTDT4/CzwbrsBaYmVBEQO7ZfH4d8ZH4/TSWuq2LxJWjuspWlVdg6equu5zdY1l9a5jXDFeXeMdRyV0kbByXEL/x+bD3PryZ6ctT9i23E7mdkGnXtGOQiRuOC6hj+jViV9+c8QpyzLTkvnaCI114jhuF/QY0fx2IhISxyX0Qd07MijRHybGC48G1hIJJw0SItFRUw0nj+uhqEgYKaFLdHhKfa96KCoSNkroEh3uEt+rSugiYaOELtFR1+1fCV0kXBz3UFQirHAtfLUq8uc5ttP3qhK6SNgoocup/vZ/4OD69jlXSibk5LXPuUQSgBK6nKqiGM76F7j00cifKzkNUtIjfx6RBKGELqfyuCCrO6R3inYkItJCeigq9aq9at1XTNMAAAdjSURBVBsu4mBK6FJPbcNFHE0JXerVNiVUCV3EkZTQpZ5bU8KJOJkSutTz+HtvqspFxJGU0KWeW1UuIk6mhC711B1fxNGU0KWeSugijqaELvU8LkjJgNSMaEciIq2ghC713JpBSMTJlNClnrtE1S0iDqaxXBJVaSGU7GmwbJ8eiIo4mBJ6onp2NpTsPn35qCvbPxYRCQsl9ER1/IBvmNwJN5y6/IzRUQlHRNpOCT0RVbmh+iT0HAUDp0U7GhEJEz0UTUQas0UkLimhJyKNqigSl5TQE5FbXfxF4pESeiJy+0dVVAldJK4ooSciDcIlEpeU0BORBuESiUtK6InI4wIMZHSJdiQiEkZK6InI7YKMzpCUHO1IRCSMlNATkcel6haROKSEnojcJXogKhKHQkroxphZxphtxpgCY8zPgmwzwxiz3hiz2RizLLxhSli5VUIXiUfNjuVijEkGHgcuAgqBT40xb1lrtwRskw38X2CWtfYrY0yPSAV8Cm8l1Hjb5VRxxV0CnXtFOwoRCbNQBueaBBRYa3cBGGNeBeYAWwK2+Q7w39barwCstUfCHehpDqyHp78GNVURP1VcGnh+tCMQkTALJaH3AfYFfC4EJjfYZhiQaoz5COgEPGqtfb7hgYwx84H5AP37929NvPWKdviS+dQfQWbXth0r0RgDIy6LdhQiEmahJHTTyDLbyHEmADOBTGCVMWa1tXb7KTtZuwhYBJCfn9/wGC1T29vxnNuhY/c2HUpEJB6EktALgX4Bn/sCBxrZpshaewI4YYxZDowFthMpteORqLWGiAgQWiuXT4GhxpiBxpg0YC7wVoNt/gqcb4xJMcZ0wFclszW8oTbgdkFqFiSnRvQ0IiJO0WwJ3VrrNcbcBrwHJAOLrbWbjTE3+9c/aa3daox5F9gA1ABPW2s3RTJwPC6VzkVEAoQ0BZ219h3gnQbLnmzw+ffA78MXWjPcLs24IyISwLk9RdV9XUTkFM5N6G5VuYiIBHJwQi9RCV1EJIBzE7oeioqInMKZCd1bCVUVKqGLiARwZkLXnJgiIqdxZkKvnRNTzRZFROo4M6F7NMmxiEhDzkvoBUvgLxf53qvKRUSkTkg9RWNKemcYOcc3Y33Ps6IdjYhIzHBeQu83CfqdNtS6iEjCc16Vi4iINEoJXUQkTiihi4jECSV0EZE4oYQuIhInlNBFROKEErqISJxQQhcRiRPGWhudExtzFNjbyt27AUVhDCeadC2xSdcSm3QtMMBa272xFVFL6G1hjFlrrc2PdhzhoGuJTbqW2KRraZqqXERE4oQSuohInHBqQl8U7QDCSNcSm3QtsUnX0gRH1qGLiMjpnFpCFxGRBpTQRUTihOMSujFmljFmmzGmwBjzs2jH01LGmD3GmI3GmPXGmLX+ZV2NMe8bY3b4X2Ny9mtjzGJjzBFjzKaAZUFjN8b83H+fthljvh6dqBsX5FoWGmP2++/NemPMNwLWxeS1GGP6GWOWGmO2GmM2G2N+5F/uuPvSxLU48b5kGGPWGGO+8F/Lr/3LI3tfrLWO+QGSgZ3AICAN+AIYGe24WngNe4BuDZY9CPzM//5nwO+iHWeQ2KcB44FNzcUOjPTfn3RgoP++JUf7Gpq5loXAjxvZNmavBegFjPe/7wRs98fruPvSxLU48b4YoKP/fSrwCTAl0vfFaSX0SUCBtXaXtbYSeBWYE+WYwmEO8Jz//XPA5VGMJShr7XKguMHiYLHPAV611p601u4GCvDdv5gQ5FqCidlrsdYetNZ+5n9fBmwF+uDA+9LEtQQTy9dirbXl/o+p/h9LhO+L0xJ6H2BfwOdCmr7hscgC/zDGrDPGzPcv62mtPQi+P2qgR9Sia7lgsTv1Xt1mjNngr5Kp/TrsiGsxxuQB4/CVBh19XxpcCzjwvhhjko0x64EjwPvW2ojfF6cldNPIMqe1u5xqrR0PXALcaoyZFu2AIsSJ9+oJYDBwNnAQeNi/POavxRjTEXgDuMNae7ypTRtZFuvX4sj7Yq2tttaeDfQFJhljzmpi87Bci9MSeiHQL+BzX+BAlGJpFWvtAf/rEeBNfF+rDhtjegH4X49EL8IWCxa74+6Vtfaw/x9hDfAU9V95Y/pajDGp+BLgS9ba//YvduR9aexanHpfallrXcBHwCwifF+cltA/BYYaYwYaY9KAucBbUY4pZMaYLGNMp9r3wMXAJnzXcL1/s+uBv0YnwlYJFvtbwFxjTLoxZiAwFFgThfhCVvsPze8KfPcGYvhajDEG+Auw1Vr7h4BVjrsvwa7FofeluzEm2/8+E/ga8CWRvi/RfhrciqfH38D39Hsn8Itox9PC2Afhe5L9BbC5Nn4gF/gA2OF/7RrtWIPE/wq+r7xV+EoUP2gqduAX/vu0Dbgk2vGHcC0vABuBDf5/YL1i/VqA8/B9Nd8ArPf/fMOJ96WJa3HifRkDfO6PeRPwK//yiN4Xdf0XEYkTTqtyERGRIJTQRUTihBK6iEicUEIXEYkTSugiInFCCV1EJE4ooYuIxIn/Bb8V5Fr9ForCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6092745661735535, 0.6666667]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 1ms/sample - loss: 1.1625 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.1552 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 1.1486 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 1.1427 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.1358 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.1294 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.1234 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.1175 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 1.1113 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.1052 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 1.0991 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0926 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 1.0863 - accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0800 - accuracy: 0.3333\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0738 - accuracy: 0.3333\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0673 - accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 1.0613 - accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 1.0550 - accuracy: 0.3333\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0494 - accuracy: 0.3333\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 1.0435 - accuracy: 0.3333\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 1.0381 - accuracy: 0.3267\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0327 - accuracy: 0.3267\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 1.0275 - accuracy: 0.3267\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0221 - accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0172 - accuracy: 0.3200\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 1.0125 - accuracy: 0.3200\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0077 - accuracy: 0.3200\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 1.0028 - accuracy: 0.3200\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.9985 - accuracy: 0.3267\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.9938 - accuracy: 0.3267\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.9897 - accuracy: 0.3267\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.9851 - accuracy: 0.3733\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.9809 - accuracy: 0.4133\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.9767 - accuracy: 0.4133\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.9726 - accuracy: 0.4133\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.9682 - accuracy: 0.4067\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9640 - accuracy: 0.4133\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9597 - accuracy: 0.4333\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9556 - accuracy: 0.4600\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.9514 - accuracy: 0.4733\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9472 - accuracy: 0.4600\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9432 - accuracy: 0.4733\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9391 - accuracy: 0.4667\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9351 - accuracy: 0.4600\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9310 - accuracy: 0.4733\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9271 - accuracy: 0.4800\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9233 - accuracy: 0.4733\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.9192 - accuracy: 0.4867\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9154 - accuracy: 0.4933\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9114 - accuracy: 0.5133\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9076 - accuracy: 0.5267\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9037 - accuracy: 0.5333\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8999 - accuracy: 0.5600\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8961 - accuracy: 0.5600\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8924 - accuracy: 0.5933\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8885 - accuracy: 0.6067\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.8848 - accuracy: 0.6067\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8811 - accuracy: 0.6200\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.8773 - accuracy: 0.6200\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.8738 - accuracy: 0.6200\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8701 - accuracy: 0.6267\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8665 - accuracy: 0.6133\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8630 - accuracy: 0.6133\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8596 - accuracy: 0.6133\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8561 - accuracy: 0.6200\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.8527 - accuracy: 0.6333\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8494 - accuracy: 0.6267\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8461 - accuracy: 0.6400\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8430 - accuracy: 0.6600\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8397 - accuracy: 0.6600\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8364 - accuracy: 0.6533\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8332 - accuracy: 0.6533\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.8302 - accuracy: 0.6533\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8271 - accuracy: 0.6533\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8239 - accuracy: 0.6600\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.8209 - accuracy: 0.6600\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8179 - accuracy: 0.6600\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8148 - accuracy: 0.6600\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8120 - accuracy: 0.6600\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8088 - accuracy: 0.6600\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8060 - accuracy: 0.6667\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.8031 - accuracy: 0.6667\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.8001 - accuracy: 0.6667\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7973 - accuracy: 0.6667\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.7944 - accuracy: 0.6667\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7917 - accuracy: 0.6667\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.7888 - accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.7861 - accuracy: 0.6667\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.7834 - accuracy: 0.6667\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7808 - accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7780 - accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7753 - accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7727 - accuracy: 0.6667\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7702 - accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 51us/sample - loss: 0.7675 - accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7649 - accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7767 - accuracy: 0.65 - 0s 47us/sample - loss: 0.7624 - accuracy: 0.6667\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7599 - accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7575 - accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7549 - accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7524 - accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7500 - accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.7476 - accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7452 - accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7427 - accuracy: 0.6667\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.7403 - accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7379 - accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.7358 - accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7334 - accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7310 - accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7288 - accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7265 - accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.7243 - accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7221 - accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7200 - accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.7178 - accuracy: 0.6667\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7156 - accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.7134 - accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7113 - accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7093 - accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.7072 - accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.7051 - accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.7030 - accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.7011 - accuracy: 0.6667\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6991 - accuracy: 0.6667\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6971 - accuracy: 0.6667\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6951 - accuracy: 0.6667\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6932 - accuracy: 0.6667\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6913 - accuracy: 0.6667\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6894 - accuracy: 0.6667\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 48us/sample - loss: 0.6873 - accuracy: 0.6667\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.6855 - accuracy: 0.6667\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.6838 - accuracy: 0.6667\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.6818 - accuracy: 0.6667\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6800 - accuracy: 0.6667\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6782 - accuracy: 0.6667\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6763 - accuracy: 0.6667\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6745 - accuracy: 0.6667\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.6728 - accuracy: 0.6667\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6710 - accuracy: 0.6667\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6692 - accuracy: 0.6667\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6675 - accuracy: 0.6667\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6658 - accuracy: 0.6667\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6641 - accuracy: 0.6667\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.6623 - accuracy: 0.6667\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.6606 - accuracy: 0.6667\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6590 - accuracy: 0.6667\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6573 - accuracy: 0.6667\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6557 - accuracy: 0.6667\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6540 - accuracy: 0.6667\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6524 - accuracy: 0.6667\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6508 - accuracy: 0.6667\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6491 - accuracy: 0.6667\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6476 - accuracy: 0.6667\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6460 - accuracy: 0.6667\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6444 - accuracy: 0.6667\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6429 - accuracy: 0.6667\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6414 - accuracy: 0.6667\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6398 - accuracy: 0.6667\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6383 - accuracy: 0.6667\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6368 - accuracy: 0.6667\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6353 - accuracy: 0.6667\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6339 - accuracy: 0.6667\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6324 - accuracy: 0.6667\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.6309 - accuracy: 0.6667\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6294 - accuracy: 0.6667\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6280 - accuracy: 0.6667\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6266 - accuracy: 0.6667\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6252 - accuracy: 0.6667\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6238 - accuracy: 0.6667\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 56us/sample - loss: 0.6223 - accuracy: 0.6667\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6209 - accuracy: 0.6667\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6196 - accuracy: 0.6667\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6182 - accuracy: 0.6667\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.6168 - accuracy: 0.6667\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6155 - accuracy: 0.6667\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6142 - accuracy: 0.6667\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6127 - accuracy: 0.6667\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6115 - accuracy: 0.6667\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6101 - accuracy: 0.6667\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6088 - accuracy: 0.6667\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6075 - accuracy: 0.6667\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6062 - accuracy: 0.6667\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.6049 - accuracy: 0.6667\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6036 - accuracy: 0.6667\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6023 - accuracy: 0.6667\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.6011 - accuracy: 0.6667\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5998 - accuracy: 0.6667\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5986 - accuracy: 0.6667\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5974 - accuracy: 0.6667\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5961 - accuracy: 0.6667\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5950 - accuracy: 0.6667\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5937 - accuracy: 0.6667\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5925 - accuracy: 0.6667\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5913 - accuracy: 0.6667\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5901 - accuracy: 0.6667\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5889 - accuracy: 0.6667\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5877 - accuracy: 0.6667\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5865 - accuracy: 0.6667\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5853 - accuracy: 0.6667\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5842 - accuracy: 0.6667\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5830 - accuracy: 0.6667\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5819 - accuracy: 0.6667\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5807 - accuracy: 0.6667\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5795 - accuracy: 0.6667\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5784 - accuracy: 0.6667\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5773 - accuracy: 0.6667\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5762 - accuracy: 0.6667\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5750 - accuracy: 0.6667\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5739 - accuracy: 0.6667\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5728 - accuracy: 0.6733\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5717 - accuracy: 0.6733\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5706 - accuracy: 0.6733\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5695 - accuracy: 0.6733\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5684 - accuracy: 0.6800\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5674 - accuracy: 0.6800\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5662 - accuracy: 0.6800\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.5652 - accuracy: 0.6867\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5641 - accuracy: 0.6933\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5631 - accuracy: 0.7000\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5620 - accuracy: 0.7000\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5610 - accuracy: 0.7000\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5599 - accuracy: 0.7000\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5590 - accuracy: 0.6933\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5579 - accuracy: 0.7000\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5569 - accuracy: 0.7000\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5558 - accuracy: 0.7000\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5548 - accuracy: 0.7000\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5538 - accuracy: 0.7000\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5528 - accuracy: 0.7000\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5519 - accuracy: 0.7000\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5509 - accuracy: 0.7067\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5499 - accuracy: 0.7067\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5490 - accuracy: 0.7067\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5480 - accuracy: 0.7067\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5470 - accuracy: 0.7067\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5460 - accuracy: 0.7067\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5451 - accuracy: 0.7067\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5441 - accuracy: 0.7067\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5432 - accuracy: 0.7133\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5421 - accuracy: 0.7133\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5412 - accuracy: 0.7133\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5403 - accuracy: 0.7200\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5393 - accuracy: 0.7200\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5384 - accuracy: 0.7200\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5374 - accuracy: 0.7200\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5365 - accuracy: 0.7200\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5357 - accuracy: 0.7200\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5346 - accuracy: 0.7200\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5337 - accuracy: 0.7200\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5328 - accuracy: 0.7200\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.5319 - accuracy: 0.7200\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5310 - accuracy: 0.7200\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.5301 - accuracy: 0.7200\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5292 - accuracy: 0.7267\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5282 - accuracy: 0.7267\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5273 - accuracy: 0.7267\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5264 - accuracy: 0.7267\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5254 - accuracy: 0.7267\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5245 - accuracy: 0.7333\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5235 - accuracy: 0.7333\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5223 - accuracy: 0.7333\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5213 - accuracy: 0.7400\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5203 - accuracy: 0.7400\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5195 - accuracy: 0.7467\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5186 - accuracy: 0.7467\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5175 - accuracy: 0.7467\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.5165 - accuracy: 0.7467\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5156 - accuracy: 0.7467\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5147 - accuracy: 0.7467\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5139 - accuracy: 0.7533\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5128 - accuracy: 0.7533\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5118 - accuracy: 0.7533\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5108 - accuracy: 0.7533\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5099 - accuracy: 0.7533\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5089 - accuracy: 0.7600\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5080 - accuracy: 0.7667\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5070 - accuracy: 0.7733\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5061 - accuracy: 0.7733\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5052 - accuracy: 0.7733\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.5043 - accuracy: 0.7733\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5031 - accuracy: 0.7733\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 40us/sample - loss: 0.5021 - accuracy: 0.7800\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.5010 - accuracy: 0.7800\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.4999 - accuracy: 0.7800\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.4987 - accuracy: 0.7867\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.4975 - accuracy: 0.7933\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4960 - accuracy: 0.7933\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4945 - accuracy: 0.8067\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.4927 - accuracy: 0.8067\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4910 - accuracy: 0.8133\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4895 - accuracy: 0.8200\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.4881 - accuracy: 0.8200\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4865 - accuracy: 0.8200\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4853 - accuracy: 0.8400\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4836 - accuracy: 0.8533\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4822 - accuracy: 0.8533\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.4806 - accuracy: 0.8533\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.4794 - accuracy: 0.8533\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 47us/sample - loss: 0.4776 - accuracy: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x203fc2e4ba8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Single New Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
